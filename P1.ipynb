{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDCND - Project 1: Finding Lane Lines;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules.\n",
    "I opted out from using moviepy as OpenCV already has a robust functionality of processing frames in video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Created on Jan 2, 2017\n",
    "\n",
    "@author: iskandar\n",
    "'''\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('/usr/local/lib/python3.5/site-packages');\n",
    "\n",
    "import matplotlib.pyplot as plt;\n",
    "import matplotlib.image as mpimg;\n",
    "import numpy as np;\n",
    "import cv2;\n",
    "import math;\n",
    "from scipy import stats;\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "from IPython.display import HTML;\n",
    "\n",
    "NoneType = type(None); #back to python 2.7 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Initialize configuration.\n",
    "I decided to combine YELLOW and WHITE color ranges in one array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "        'rho': 2,\n",
    "        'theta': np.pi / 180,\n",
    "        'threshold': 30,\n",
    "        'min_line_len': 10,\n",
    "        'max_line_gap': 1,\n",
    "        'kernel': 3,\n",
    "        'edge_low_threshold': 50,\n",
    "        'edge_high_threshold': 150,\n",
    "        'poly_left_bottom': [0, 539],\n",
    "        'poly_right_bottom': [960, 539],\n",
    "        'poly_apex': [470, 315],\n",
    "        'low_color_threshold': np.array([0, 140, 200], dtype = \"uint8\"),\n",
    "        'high_color_threshold': np.array([255, 255, 255], dtype = \"uint8\")\n",
    "        };\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    (assuming your grayscaled image is called 'gray')\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to draw trapezoid on every frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polygon(shape):\n",
    "    \"\"\"\n",
    "    Returns trapezoid for the image as a region of interest.\n",
    "    \"\"\"\n",
    "    \n",
    "    x_ratio = 0.95;\n",
    "    y_ratio = 0.62;\n",
    "    x_mid_ratio = 0.3;\n",
    "    \n",
    "    magnitude_x = shape[1];\n",
    "    magnitude_y = shape[0]; \n",
    "    \n",
    "    vertices = np.array([\n",
    "                          [\n",
    "                            (int(magnitude_x * (1 - x_ratio)), magnitude_y), \n",
    "                            (int(magnitude_x / 3), int(magnitude_y * y_ratio)), \n",
    "                            (int(magnitude_x / 3) + int(magnitude_x * x_mid_ratio), int(magnitude_y * y_ratio)), \n",
    "                            (int(magnitude_x * x_ratio), magnitude_y)\n",
    "                          ]\n",
    "                         ], dtype=np.int32);\n",
    "\n",
    "\n",
    "    return vertices;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poly_len(vertices):\n",
    "        \n",
    "    left_side = euclidean(vertices[0][0], vertices[0][1]);\n",
    "    right_side = euclidean(vertices[0][2], vertices[0][3]);\n",
    "    \n",
    "    upper_base = euclidean(vertices[0][1], vertices[0][2]);\n",
    "    lower_base = euclidean(vertices[0][0], vertices[0][3]);\n",
    "    \n",
    "    return (int(left_side), int(right_side), int(upper_base), int(lower_base));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap, polygon):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines, polygon=polygon)\n",
    "    return line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "def color_filter(image):\n",
    "    \n",
    "    filter = cv2.inRange(image, param['low_color_threshold'], param['high_color_threshold']);\n",
    "    final_filter = cv2.bitwise_and(image, image, mask=filter);\n",
    "    return final_filter;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function to draw lines on a frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_lines(img, lines, color=[0, 255, 0], thickness=2, polygon=None):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    avg = 0x0;\n",
    "    avg_left_slope = 0x0;\n",
    "    avg_right_slope = 0x0;\n",
    "    \n",
    "    left_slope = []\n",
    "    right_slope = []\n",
    "    \n",
    "    x_right_line = [];\n",
    "    y_right_line = [];\n",
    "    \n",
    "    x_left_line  = [];\n",
    "    y_left_line = [];\n",
    "    \n",
    "    right_line = [];\n",
    "    left_line = [];\n",
    "    x_center = img.shape[0x1] / 2;\n",
    "    \"\"\"\n",
    "    y=mx+b\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            \n",
    "            \n",
    "            \n",
    "            slope = ((y2-y1)/(x2-x1));\n",
    "            \n",
    "            if(x1 > x_center and x2 > x_center):\n",
    "                right_line.append(line);\n",
    "            else:\n",
    "                left_line.append(line);\n",
    "                \n",
    "            if(slope < 0x0):\n",
    "                left_slope.append(slope);\n",
    "                \n",
    "            elif(slope >= 0x0):\n",
    "                right_slope.append(slope);\n",
    "            \n",
    "            for i in left_line:\n",
    "                for x1,y1,x2,y2 in i:\n",
    "                    x_left_line.append(x1);\n",
    "                    x_left_line.append(x2);\n",
    "                    y_left_line.append(y1);\n",
    "                    y_left_line.append(y2);\n",
    "            \n",
    "            for i in right_line:\n",
    "                for x1,y1,x2,y2 in i:\n",
    "                    x_right_line.append(x1);\n",
    "                    x_right_line.append(x2);\n",
    "                    y_right_line.append(y1);\n",
    "                    y_right_line.append(y2);\n",
    "\n",
    "\n",
    "        \n",
    "    #y = mx + b\n",
    "    left_m, left_b, left_r, left_p, left_std_err = stats.linregress(x_left_line, y_left_line);\n",
    "\n",
    "\n",
    "    right_m, right_b, right_r, right_p, right_std_err = stats.linregress(x_right_line, y_right_line);\n",
    "    \n",
    "    poly_left = polygon[0];\n",
    "    poly_right = polygon[1];\n",
    "    \n",
    "    upper_base = polygon[2];\n",
    "    lower_base = polygon[3];\n",
    "    \n",
    "    #based on: height = sqrt(side_1^2 - ((side_1^2 - side_2^2 + d^2)/2d)2)\n",
    "    trapezoid_height = math.sqrt(math.pow(poly_left, 0x2) - 0x2 * ((math.pow(poly_left, 0x2) - math.pow(poly_right, 0x2) + math.pow(lower_base - upper_base, 0x2))/(0x2 * (lower_base - upper_base))));\n",
    "    \n",
    "    #x = (y - b)/m\n",
    "    y1 = img.shape[0];\n",
    "    y2 = int(trapezoid_height);\n",
    "    \n",
    "    right_x1 = int((y1 - right_b) / right_m)\n",
    "    right_x2 = int((y2 - right_b) / right_m)\n",
    "    \n",
    "    left_x1 = int((y1 - left_b) / left_m)\n",
    "    left_x2 = int((y2 - left_b) / left_m)    \n",
    "                    \n",
    "    avg_left_slope = np.mean(left_slope, dtype=np.float)\n",
    "#    avg_right_slope = np.mean(right_slope, dtype=np.float);\n",
    "    \n",
    "    cv2.line(img, (right_x1, y1), (right_x2, y2), color, thickness)\n",
    "    cv2.line(img, (left_x1, y1), (left_x2, y2), color, thickness)\n",
    "                #cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap, polygon):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines, polygon=polygon)\n",
    "    return line_img;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caller function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process():\n",
    "\n",
    "\n",
    "    cap = cv2.VideoCapture('resources/video/solidYellowLeft.mp4')\n",
    "    outfilename = 'resources/video/result/outputSolidYellowLeft.mp4';\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "    \n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5)\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n",
    "    \n",
    "    out = cv2.VideoWriter(outfilename, fourcc, 20, (width,height));\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        ret, image = cap.read()\n",
    "        if not (isinstance(image, NoneType)):\n",
    "            poly = polygon(image.shape);\n",
    "    \n",
    "            poly_length = poly_len(poly);\n",
    "    \n",
    "            filtered_image = color_filter(image);\n",
    "\n",
    "            gray = grayscale(filtered_image);\n",
    "    \n",
    "            blur_image = gaussian_blur(gray, param['kernel']);\n",
    "\n",
    "            edge_masked = canny(blur_image, param['edge_low_threshold'], param['edge_high_threshold'])\n",
    "    \n",
    "            masked = region_of_interest(edge_masked, poly)\n",
    "    \n",
    "            hough = hough_lines(masked, param['rho'], param['theta'], param['threshold'], param['min_line_len'], param['max_line_gap'], poly_length);\n",
    "    \n",
    "            res = weighted_img(hough, image);\n",
    "    \n",
    "            cv2.imshow('image', res);\n",
    "\n",
    "            out.write(res);\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release();\n",
    "    out.release();\n",
    "    cv2.destroyAllWindows();\n",
    "    return outfilename;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(process()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
